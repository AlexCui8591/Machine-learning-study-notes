# This is a note focusing on machine learning enigeering 
This project covers a lot of machine learning knowledge and project content in the learning process, learning by doing. Any comments and discussions are welcome!
### So let's start with the simplest neural network below!

## Steps in Writing a Neural Network

When building a neural network from scratch, the process can be divided into several key steps:

1. **Define Activation Functions**  
   Implement common activation functions (e.g., Sigmoid, ReLU, Tanh) that introduce non-linearity into the model.

## Activation Functions

Activation functions introduce non-linearity into neural networks and help determine whether a neuron should be activated.  
They map input signals into specific ranges (e.g., probabilities or bounded values), making deep learning models expressive and powerful.

---

### 1. Sigmoid
**Formula:**  
\[
\sigma(x) = \frac{1}{1 + e^{-x}}
\]

- Output range: (0, 1)  
- Commonly used in **binary classification**.  
- Limitation: suffers from the **vanishing gradient problem**.

<p align="center">
  <img src="https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg" width="400"/>
</p>

---

### 2. Tanh
**Formula:**  
\[
\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
\]

- Output range: (-1, 1)  
- Zero-centered, better than sigmoid for convergence.  
- Still prone to **vanishing gradients**.

<p align="center">
  <img src="https://upload.wikimedia.org/wikipedia/commons/c/cb/Activation_tanh.svg" width="400"/>
</p>

---

### 3. ReLU (Rectified Linear Unit)
**Formula:**  
\[
f(x) = \max(0, x)
\]

- Keeps positive values unchanged, replaces negatives with 0.  
- Helps **mitigate vanishing gradients** and speeds up training.  
- Limitation: may lead to **dead neurons** (outputs stuck at 0).

<p align="center">
  <img src="https://upload.wikimedia.org/wikipedia/commons/6/6c/Rectifier_and_softplus_functions.svg" width="400"/>
</p>

---

### 4. Leaky ReLU
**Formula:**  
\[
f(x) = 
\begin{cases} 
x & \text{if } x \geq 0 \\ 
\alpha x & \text{if } x < 0 
\end{cases}
\]

- Introduces a small slope (\(\alpha \approx 0.01\)) for negative values.  
- Prevents the **dead neuron problem** in ReLU.  

<p align="center">
  <img src="https://upload.wikimedia.org/wikipedia/commons/a/ae/Activation_prelu.svg" width="400"/>
</p>

---

### 5. ELU (Exponential Linear Unit)
**Formula:**  
\[
f(x) = 
\begin{cases} 
x & \text{if } x \geq 0 \\ 
\alpha (e^x - 1) & \text{if } x < 0 
\end{cases}
\]

- Smooths the negative part compared to ReLU.  
- Helps reduce bias shift and improve training.



---

### 6. Softmax
**Formula:**  
\[
\sigma(z)_i = \frac{e^{z_i}}{\sum_{j=1}^K e^{z_j}}
\]

- Converts logits into a **probability distribution**.  
- Used in the **output layer for multi-class classification**.



   

3. **Implement Loss Functions**  
## Common Loss Functions

Loss functions measure the error between predictions and ground truth, guiding parameter updates via backpropagation.  
Below are several widely used loss functions grouped by task.

The loss function is mainly used in the training phase of the model. After each batch of training data is fed into the model, the predicted values are output through forward propagation, and then the loss function calculates the difference between the predicted values and the true values, i.e. the loss value. After obtaining the loss value, the model updates each parameter through backpropagation to reduce the loss between the true value and the predicted value, so that the predicted value generated by the model is closer to the true value, thus achieving the purpose of learning.
After the training of the model, the model has been back-propagated to make each parameter optimal. So the results obtained by using this model for prediction must be close to the real results.


### ðŸ”¹ Regression

#### 1. Mean Absolute Error (MAE)

**Formula:**  

L_{\text{MSE}}=\frac{1}{n}\sum_{i=1}^{n}\left(\hat{y}_i-y_i\right)^2


**Fallback:** `L_MSE = (1/n) * sum_{i=1..n} (y_hat_i - y_i)^2`

- More robust to outliers than MSE.  
- Gradient is less smooth (may converge slower).  


---

#### 2. Huber Loss
**Formula:**  
\[
L_\delta(a) =
\begin{cases}
\frac{1}{2}a^2 & \text{if } |a| \leq \delta \\
\delta(|a| - \tfrac{1}{2}\delta) & \text{otherwise}
\end{cases}
\]

- Combines MSE (for small errors) and MAE (for large errors).  
- Robust against outliers, smooth near zero.  



---

### ðŸ”¹ Classification

#### 1. Hinge Loss
**Formula:**  
\[
L = \sum_{i=1}^{n} \max(0, 1 - y_i \hat{y}_i)
\]

- Used in **Support Vector Machines (SVM)**.  
- Encourages a margin between classes.  



---

#### 2. Focal Loss
**Formula:**  
\[
L = - \alpha (1 - \hat{y}_i)^\gamma y_i \log(\hat{y}_i)
\]

- Emphasizes **hard-to-classify samples**.  
- Commonly used in **object detection** (e.g., RetinaNet).  


---

### ðŸ”¹ Generative Models

#### 1. KL Divergence
**Formula:**  
\[
D_{KL}(P || Q) = \sum_x P(x) \log \frac{P(x)}{Q(x)}
\]

- Measures the distance between two probability distributions.  
- Widely used in **Variational Autoencoders (VAE)**.  


---

#### 2. GAN Loss (Adversarial Loss)
**Formula:**  
\[
\min_G \max_D \; \mathbb{E}_{x \sim p_{data}}[\log D(x)] +
\mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))]
\]

- Used in **Generative Adversarial Networks (GANs)**.  
- Generator and discriminator compete in a minimax game.  




5. **Design Layers**  
   Construct layers such as input, hidden, and output layers, and define how neurons are connected.

6. **Build Optimizers**  
   Implement optimization algorithms (e.g., Gradient Descent, Adam) to update the weights and biases efficiently.

7. **Combine and Train the Network**  
   Integrate activation functions, loss functions, layers, and optimizers into a complete neural network.  
   Train the model by iteratively forward-propagating inputs, calculating the loss, backpropagating gradients, and updating parameters.
